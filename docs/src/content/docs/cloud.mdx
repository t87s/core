---
title: t87s Cloud
description: The sales pitch you've been waiting for
---

import { Tabs, TabItem } from '@astrojs/starlight/components';

Sometimes, when you vacation in Florida, a glitzy salesman corners you with free coffee and a timeshare pitch. In t87s, that time is now.

## Why Cloud?

Look, we built the open-source library because we love caching. We built the cloud because we love money. But also because self-hosting cache infrastructure is a pain in the ass and we're genuinely good at it.

Our cloud is:

**Fast.** Sub-millisecond response times. We're talking 0.3ms p50, 0.8ms p99.

**Scalable.** We're built on Cloudflare using their globally distributed network.

**Smart.** Real-time cache optimization via AI analysis. We analyze your cache patterns and auto-tune TTLs so you don't have to guess.

**Simple.** One API key. No Redis cluster to babysit.

## Benchmarks

| Adapter | p50 | p99 | Ops/sec |
|---------|-----|-----|---------|
| Memory | 0.01ms | 0.05ms | ∞ (local) |
| Redis | 1.2ms | 4.5ms | 50k |
| t87s Cloud | 0.3ms | 0.8ms | 500k |

Yes, we're faster than Redis for a globally distributed app. No, we didn't stack the deck in our favor. Yes, the benchmarks are [open source](https://github.com/t87s/core/tree/main/benchmarks), and you can reproduce them at your leisure.

## The API

Query your cache analytics with SQL via `POST /v1/query`.

```bash
curl -X POST https://api.t87s.dev/v1/query \
  -H "Authorization: Bearer $T87S_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"sql": "SELECT * FROM verifications LIMIT 10"}'
```

### Tables

**verifications**
key, cached_hash, fresh_hash, is_stale, timestamp

**cache_operations**
type, key, timestamp

**invalidations**
id, tag, exact, timestamp

**invalidated**
key, invalidation_id, matched_tag, timestamp

### Example Queries

Staleness by key.

```sql
SELECT key, COUNT(*) as samples, SUM(is_stale) as stale,
       ROUND(SUM(is_stale) * 100.0 / COUNT(*), 1) as stale_pct
FROM verifications
GROUP BY key
ORDER BY samples DESC
LIMIT 100
```

Potential issues.

```sql
SELECT key, COUNT(*) as samples, SUM(is_stale) as stale,
       ROUND(SUM(is_stale) * 100.0 / COUNT(*), 1) as stale_pct
FROM verifications
GROUP BY key
HAVING COUNT(*) >= 10 AND (SUM(is_stale) * 100.0 / COUNT(*)) > 10
ORDER BY stale_pct DESC
```

Operations by type.

```sql
SELECT type, COUNT(*) as count
FROM cache_operations
GROUP BY type
```

Recent invalidations.

```sql
SELECT i.tag, i.exact, datetime(i.timestamp/1000, 'unixepoch') as time,
       COUNT(inv.id) as affected_keys
FROM invalidations i
LEFT JOIN invalidated inv ON inv.invalidation_id = i.id
GROUP BY i.id
ORDER BY i.timestamp DESC
LIMIT 50
```

Blast radius.

```sql
SELECT i.tag, i.exact, COUNT(inv.id) as affected_keys
FROM invalidations i
LEFT JOIN invalidated inv ON inv.invalidation_id = i.id
WHERE i.timestamp > (strftime('%s', 'now') - 86400) * 1000
GROUP BY i.id
ORDER BY affected_keys DESC
LIMIT 20
```

Hourly verifications.

```sql
SELECT strftime('%Y-%m-%d %H:00', timestamp/1000, 'unixepoch') as hour,
       COUNT(*) as total, SUM(is_stale) as stale
FROM verifications
GROUP BY hour
ORDER BY hour DESC
LIMIT 24
```

## Using with LLMs

The Query Explorer includes a "Prompt for LLMs" button that copies your API key and documentation to your clipboard. Paste it into Claude, ChatGPT, Cursor, or any AI assistant to analyze your cache patterns.

Ask questions like:
- "What cache issues do I have?"
- "Which keys have the highest stale rate?"
- "Should I increase the TTL on user:* keys?"

For the supremely lazy and crafty dev, one popular approach is the "dumb cache"—wrap everything in a cache call without any tags, deploy to production, and let it run for 48-72 hours. Then, use the "Prompt for LLMs" button and your favorite AI assistant to analyze your actual traffic patterns and tell you exactly which operations benefit from caching and what TTLs make sense.

## Pricing

**Free tier:** 10k operations/month. No credit card required.

**After that:** $0.001 per operation.

Let's say you have a small SaaS with 50 daily active users. Each user averages 3 sessions per day, and each session hits your cache 10 times. That's 50 × 3 × 10 = 1,500 operations per day, or about 45k per month. Subtract the 10k free tier, and you're at 35k × $0.001 = **$35/month**.

## Get Started

<Tabs>
  <TabItem label="TypeScript">
    ```typescript
    import { QueryCache, at, wild, CloudAdapter } from '@t87s/core';

    const cache = QueryCache({
      schema: at('users', () => wild),
      adapter: new CloudAdapter({ apiKey: process.env.T87S_API_KEY! }),
      queries: (tags) => ({
        getUser: (id: string) => ({
          tags: [tags.users(id)],
          fn: () => db.users.findById(id),
        }),
      }),
    });
    ```
  </TabItem>
  <TabItem label="Python">
    ```python
    import os
    from t87s import QueryCache, TagSchema, Wild, cached
    from t87s.adapters import AsyncCloudAdapter

    class Tags(TagSchema):
        users: Wild[TagSchema]

    class Cache(QueryCache[Tags]):
        @cached(Tags.users())
        async def get_user(self, id: str):
            return await db.users.find_by_id(id)

    cache = Cache(adapter=AsyncCloudAdapter(api_key=os.environ["T87S_API_KEY"]))
    ```
  </TabItem>
</Tabs>

That's it. Same API you already know. Just faster, smarter, and with someone else waking up at 3am.

[Sign up for free](https://t87s.dev/signup)
