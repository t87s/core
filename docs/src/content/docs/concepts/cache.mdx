---
title: Cache
description: The $440 million lesson you'd rather learn from someone else
---

Netflix serves 260 million subscribers across 190 countries. Their EVCache system handles 400 million operations per second across 22,000 servers. When a show like *Stranger Things* drops, they pre-warm the cache with predicted content keys hours before release. Result: 99.99% cache hit rate. Ten million people hit play, and the database barely notices.

If Netflix didn't cache, every single one of those ten million requests would hit their database directly. The database would melt. The show would buffer. Twitter would explode with complaints. Instead, the cache absorbs the load, the stream starts instantly, and everyone's happy. This is why we cache.

In 2010, Facebook went dark for hours. Unfortunately, it came back, but it was a hopeful moment for many of us. The cause? A cache invalidation bug. Their automated system tried to fix an invalid config value in cache, but the fix required a database query. Every client saw the bad value simultaneously. Every client tried to fix it simultaneously. Hundreds of thousands of queries per second hammered the database cluster until it collapsed. Facebook had to turn off the entire site to recover.

This is what happens when caching goes wrong.

## To cache or not to cache?

Premature optimization is the root of all evil. So never start a project out with cache in mind. But at a certain point, things will just feel slow. Caching is the best optimization, and it's also the hardest. It's the best because the best way to optimize any program is not to run it. And it's the hardest because it's really tough to know when things change and when things stay the same. But they stay the same more than you'd think, and when this is the case, you're leaving oodles of speed on the table by not caching. So cache with reckless abandon. Your users will be happy, your cloud bill will be less, and yours truly will feel like he didn't waste time writing the paragraph you're reading.
